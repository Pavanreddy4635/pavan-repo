# -*- coding: utf-8 -*-
"""CMP7005_PRAC1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kTFX3oY7b70SmxMy_TZ7UL0Dep_ltdao
"""


import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dongsi = pd.read_csv('/content/PRSA_Data_Dongsi_20130301-20170228.csv')
shunyi = pd.read_csv('/content/PRSA_Data_Shunyi_20130301-20170228.csv')
huairou = pd.read_csv('/content/PRSA_Data_Huairou_20130301-20170228.csv')
gucheng = pd.read_csv('/content/PRSA_Data_Gucheng_20130301-20170228.csv')

dongsi['site_type'] = 'urban'
dongsi['site_name'] = 'Dongsi'

shunyi['site_type'] = 'suburban'
shunyi['site_name'] = 'Shunyi'

huairou['site_type'] = 'rural'
huairou['site_name'] = 'Huairou'

gucheng['site_type'] = 'industrial'
gucheng['site_name'] = 'Gucheng'

merged_data = pd.concat([dongsi, shunyi, huairou, gucheng], ignore_index=True)

if not os.path.exists('data'):
    os.makedirs('data')

merged_data.to_csv('data/merged_data.csv', index=False)

print(f"Total records: {merged_data.shape[0]}")
print(f"Total features: {merged_data.shape[1]}")
merged_data.head()

#uoload the dataset
df = pd.read_csv('/content/data/merged_data.csv')

#print the last 5 rows
df.tail()

df.shape

df.columns

df.info()

#print the null values
df.isnull().sum()

#fill the null values with mean
df.fillna(df.mean(numeric_only=True), inplace=True)

df['wd'] = df['wd'].fillna(df['wd'].mode()[0])

print(df.isnull().sum())

df.to_csv("cleaned_air_quality.csv", index=False)

df.duplicated()

df.sample(20)

df.describe()

sns.heatmap(df.isnull(), cbar=False, yticklabels=False)
plt.title("Missing Value Heatmap")
plt.show()

df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])

df.set_index('datetime', inplace=True)

df['PM2.5'].plot(figsize=(12, 5), title="PM2.5 Trend Over Time")
plt.ylabel("PM2.5")
plt.xlabel("Time")
plt.grid()
plt.show()

station_avg = df.groupby('station')['PM2.5'].mean().sort_values(ascending=False)

station_avg.plot(kind='bar', figsize=(10, 5), title='Average PM2.5 by Station')
plt.ylabel('PM2.5')
plt.show()

fig, ax = plt.subplots(figsize=(15, 8))
for site_type in df['site_type'].unique():
    site_data = df[df['site_type'] == site_type]
    monthly_avg = site_data.groupby(pd.Grouper(level='datetime', freq='M'))['PM2.5'].mean()
    monthly_avg.plot(ax=ax, label=site_type)

plt.legend()
plt.title('Monthly Average PM2.5 by Site Type')

plt.figure(figsize=(8, 6))
sns.scatterplot(x='TEMP', y='PM2.5', data=df, alpha=0.4)
sns.regplot(x='TEMP', y='PM2.5', data=df, scatter=False, color='red')
plt.title('Temperature vs PM2.5')
plt.xlabel('Temperature (Â°C)')
plt.ylabel('PM2.5 Concentration')
plt.tight_layout()
plt.show()

pollutants = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

plt.figure(figsize=(14, 8))
for pollutant in pollutants:
    plt.plot(df[pollutant], label=pollutant, alpha=0.7)
plt.legend()
plt.title('Time Series of Air Pollutants')
plt.xlabel('Time')
plt.ylabel('Concentration')
plt.tight_layout()
plt.show()

wind_pm = df.groupby('wd')['PM2.5'].mean()

plt.figure(figsize=(10, 6))
sns.barplot(x=wind_pm.index, y=wind_pm.values, palette='viridis')
plt.title('Average PM2.5 by Wind Direction')
plt.xlabel('Wind Direction')
plt.ylabel('PM2.5 Concentration')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 4))
sns.histplot(df['PM2.5'], bins=50, kde=True)
plt.title("PM2.5 Distribution")
plt.xlabel("PM2.5")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(8, 4))
sns.scatterplot(x='TEMP', y='PM2.5', data=df, hue='site_type', alpha=0.7)
plt.title("PM2.5 vs Temperature by Site Type")
plt.xlabel("Temperature (Â°C)")
plt.ylabel("PM2.5")
plt.show()

plt.figure(figsize=(12, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

sns.pairplot(df[pollutants].dropna())
plt.suptitle('Pairplot of Pollutants', y=1.02)
plt.show()

pollutant_columns = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

def remove_outliers_iqr(df, columns):
    for col in columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
    return df

import matplotlib.pyplot as plt
import seaborn as sns

pollutant_columns = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3']

df_cleaned = remove_outliers_iqr(df.copy(), pollutant_columns)
fig, axes = plt.subplots(2, len(pollutant_columns), figsize=(18, 8))
fig.suptitle('Boxplots Before and After Outlier Removal', fontsize=16)

for i, col in enumerate(pollutant_columns):
    sns.boxplot(y=df[col], ax=axes[0, i], color="salmon")
    axes[0, i].set_title(f"{col} (Before)")
    axes[0, i].set_xlabel("")
    axes[0, i].set_ylabel("")

for i, col in enumerate(pollutant_columns):
    sns.boxplot(y=df_cleaned[col], ax=axes[1, i], color="skyblue")
    axes[1, i].set_title(f"{col} (After)")
    axes[1, i].set_xlabel("")
    axes[1, i].set_ylabel("")

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""FEATURE ENGINEERING /FEATURE SCALING"""

numerical_cols = ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP',
                  'WSPM', 'temp_dew_point_diff', 'hour', 'day', 'month', 'day_of_week']
categorical_cols = ['wd', 'station', 'site_type', 'is_weekend', 'is_peak_hour']

print("ðŸ”¢ Numerical Features:")
print(numerical_cols)

print("\nðŸ”¤ Categorical Features:")
print(categorical_cols)

df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])
df.set_index('datetime', inplace=True)

df.drop(columns=['year', 'month', 'day', 'hour'], inplace=True)

print("âœ… Remaining columns after dropping year, month, day, and hour:")
print(df.columns)

df.sample(10)

def categorize_pm25(value):
    if value <= 12:
        return 'Good'
    elif value <= 35.4:
        return 'Moderate'
    elif value <= 55.4:
        return 'Unhealthy for Sensitive Groups'
    elif value <= 150.4:
        return 'Unhealthy'
    elif value <= 250.4:
        return 'Very Unhealthy'
    else:
        return 'Hazardous'

df['PM2.5_Category'] = df['PM2.5'].apply(categorize_pm25)

df = pd.get_dummies(df, columns=['wd', 'station'], prefix=['wind', 'station'], drop_first=True)

print("\nEncoded categorical variables:")
print(df.filter(regex='^wind_|^station_').head())

df['PM_ratio'] = df['PM2.5'] / df['PM10']
df['PM_ratio'] = df['PM_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)

df['NO2_O3_ratio'] = df['NO2'] / df['O3']
df['NO2_O3_ratio'] = df['NO2_O3_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0)

df['total_pollution'] = df['PM2.5'] + df['PM10'] + df['SO2'] + df['NO2'] + df['CO'] + df['O3']

def calculate_pm25_aqi(pm25):
    if pm25 <= 12:
        return pm25 * 50/12
    elif pm25 <= 35.4:
        return 50 + (pm25-12) * 50/(35.4-12)
    elif pm25 <= 55.4:
        return 100 + (pm25-35.4) * 50/(55.4-35.4)
    elif pm25 <= 150.4:
        return 150 + (pm25-55.4) * 50/(150.4-55.4)
    elif pm25 <= 250.4:
        return 200 + (pm25-150.4) * 100/(250.4-150.4)
    else:
        return 300 + (pm25-250.4) * 200/(500-250.4)

df['PM25_AQI'] = df['PM2.5'].apply(calculate_pm25_aqi)

print(f"Final DataFrame shape: {df.shape}")

station_mapping = {
    'Dongsi': 'Dongsi',
    'Shunyi': 'Shunyi',
    'Huairou': 'Huairou',
    'Gucheng': 'Gucheng'
}

if 'station' not in df.columns and 'station_code' in df.columns:
    station_names = list(station_mapping.values())

    station_codes = le.transform(station_names)
    station_mapping = dict(zip(station_codes, station_names))

    df['station'] = df['station_code'].map(station_mapping)
else:

    if 'site_name' in df.columns:
        df['station'] = df['site_name'].map(station_mapping)
    else:
        for station_name in station_mapping.keys():
            column_name = f'station_{station_name}'
            if column_name in df.columns:
                df.loc[df[column_name] == 1, 'station'] = station_name

if 'station_code' not in df.columns:
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    df['station_code'] = le.fit_transform(df['station'])

if df['site_type'].dtype == 'object':
    from sklearn.preprocessing import LabelEncoder
    label_encoder = LabelEncoder()
    df['site_type'] = label_encoder.fit_transform(df['site_type'])

if df['PM2.5_Category'].dtype == 'object':
    df['PM2.5_Category'] = label_encoder.fit_transform(df['PM2.5_Category'])

bool_cols = df.select_dtypes(include='bool').columns
df[bool_cols] = df[bool_cols].astype(int)

from sklearn.preprocessing import LabelEncoder

label_cols = df.select_dtypes(include='object').columns
le = LabelEncoder()

for col in label_cols:
    df[col] = le.fit_transform(df[col])

print("\nAll numeric columns:")
print(df.dtypes)

columns_to_drop = [
     'station_Gucheng', 'station_Huairou', 'station_Shunyi','station'
]

existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]

df.drop(columns=existing_columns_to_drop, inplace=True)

print("âœ… Columns dropped successfully:")
print(existing_columns_to_drop)

print("\nâœ… Remaining columns in the DataFrame:")
print(df.columns)

df.sample(10)

df.shape

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

target = 'PM2.5'
features = df.drop(columns=[target])
X = df.drop(columns=['PM2.5'])
y = df[target]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_train)

y_pred = rf.predict(X_test_scaled)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
print("\nðŸ“Š Evaluation Metrics (Random Forest):")
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("RÂ² Score:", r2_score(y_test, y_pred))

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train_scaled, y_train)

y_pred_lr = lr.predict(X_test_scaled)

print("\nðŸ“Š Evaluation Metrics (Linear Regression):")
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lr)))
print("MAE:", mean_absolute_error(y_test, y_pred_lr))
print("RÂ² Score:", r2_score(y_test, y_pred_lr))

from sklearn.ensemble import GradientBoostingRegressor
gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
gb.fit(X_train_scaled, y_train)
y_pred_gb = gb.predict(X_test_scaled)

print("\nðŸ“Š Gradient Boosting Metrics:")
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_gb)))
print("MAE:", mean_absolute_error(y_test, y_pred_gb))
print("RÂ² Score:", r2_score(y_test, y_pred_gb))

comparison = pd.DataFrame({
    "Model": ["Random Forest", "Linear Regression", "Gradient Boosting"],
    "RMSE": [
        np.sqrt(mean_squared_error(y_test, y_pred)),
        np.sqrt(mean_squared_error(y_test, y_pred_lr)),
        np.sqrt(mean_squared_error(y_test, y_pred_gb))
    ],
    "MAE": [
        mean_absolute_error(y_test, y_pred),
        mean_absolute_error(y_test, y_pred_lr),
        mean_absolute_error(y_test, y_pred_gb)
    ],
    "RÂ² Score": [
        r2_score(y_test, y_pred),
        r2_score(y_test, y_pred_lr),
        r2_score(y_test, y_pred_gb)
    ]
})

print("\nðŸ“‹ Model Comparison:")
print(comparison)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(y_test.values[:100], label='Actual', linewidth=2)
plt.plot(y_pred[:100], label='Random Forest Prediction', linestyle='--')
plt.plot(y_pred_lr[:100], label='Linear Regression Prediction', linestyle=':')
plt.plot(y_pred_lr[:100], label='Gradient Boosting', linestyle=':')

plt.legend()
plt.title("Model Predictions vs Actual PM2.5")
plt.xlabel("Sample Index")
plt.ylabel("PM2.5 Value")
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 5))
sns.barplot(data=comparison, x='Model', y='RMSE', palette='pastel')
plt.title("RMSE Comparison of Models")
plt.ylabel("Root Mean Squared Error")
plt.tight_layout()
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(18, 5))

axs[0].scatter(y_test, y_pred, alpha=0.5)
axs[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[0].set_title("Random Forest")
axs[0].set_xlabel("Actual PM2.5")
axs[0].set_ylabel("Predicted PM2.5")

axs[1].scatter(y_test, y_pred_lr, alpha=0.5, color='orange')
axs[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[1].set_title("Linear Regression")
axs[1].set_xlabel("Actual PM2.5")
axs[1].set_ylabel("Predicted PM2.5")

axs[2].scatter(y_test, y_pred_gb, alpha=0.5, color='green')
axs[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
axs[2].set_title("Gradient Boosting")
axs[2].set_xlabel("Actual PM2.5")
axs[2].set_ylabel("Predicted PM2.5")

plt.suptitle("Actual vs Predicted PM2.5 for Each Model", fontsize=16)
plt.tight_layout()
plt.show()

!pip install gradio

import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

df = pd.DataFrame()

# ---------- Data Overview ----------
def show_data_info():
    shape = f"Rows: {df.shape[0]}, Columns: {df.shape[1]}"
    head = df.head()

    missing = df.isnull().sum().reset_index()
    missing.columns = ['Column', 'Missing Values']

    dtypes = df.dtypes.reset_index()
    dtypes.columns = ['Column', 'Data Type']

    unique_vals = df.nunique().reset_index()
    unique_vals.columns = ['Column', 'Unique Values']

    describe = df.describe().transpose().reset_index()
    describe.rename(columns={'index': 'Feature'}, inplace=True)

    if 'PM2.5' in df.columns and np.issubdtype(df['PM2.5'].dtype, np.number):
        corr = df.corr(numeric_only=True)['PM2.5'].sort_values(ascending=False).reset_index()
        corr.columns = ['Feature', 'Correlation with PM2.5']
    else:
        corr = pd.DataFrame(columns=['Feature', 'Correlation with PM2.5'])

    return shape, head, missing, dtypes, unique_vals, describe, corr

# ---------- EDA Plot (for both numeric and categorical) ----------
def plot_eda(feature):
    fig, ax = plt.subplots(figsize=(10, 5))

    if feature in df.select_dtypes(include=[np.number]).columns:
        sns.histplot(df[feature], bins=50, kde=True, ax=ax)
        ax.set_title(f"{feature} Distribution (Numeric)")
    elif feature in df.select_dtypes(include=[object]).columns:
        sns.countplot(x=df[feature], ax=ax)
        ax.set_title(f"{feature} Distribution (Categorical)")
    else:
        ax.text(0.5, 0.5, "Selected feature not numeric or categorical!", ha='center')

    plt.tight_layout()
    return fig

# ---------- Modeling ----------
def run_model(model_type):
    df_model = df.select_dtypes(include=[np.number]).dropna()
    if 'PM2.5' not in df_model.columns:
        return "âš ï¸ 'PM2.5' target column missing in dataset."

    X = df_model.drop(columns=['PM2.5'])
    y = df_model['PM2.5']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    if model_type == "Random Forest":
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    else:
        model = LinearRegression()

    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    return f"âœ… {model_type} Model trained.\nRMSE: {rmse:.2f}\nRÂ² Score: {r2:.2f}"

# ---------- File Upload ----------
def upload_file(file):
    global df
    df = pd.read_csv(file.name)
    return f"âœ… File '{file.name}' loaded successfully!", gr.update(choices=df.columns.tolist())

# ---------- Gradio Interface ----------
with gr.Blocks() as app:
    gr.Markdown("## ðŸ“Š CMP7005 Air Quality Multi-page GUI")

    with gr.Tab("ðŸ“‚ Upload Data"):
        file_input = gr.File(label="Upload CSV Dataset")
        upload_status = gr.Textbox(label="Status")
        file_input.change(fn=upload_file, inputs=file_input, outputs=[upload_status])

    with gr.Tab("ðŸ“ˆ Data Overview"):
        shape_out = gr.Textbox(label="Dataset Shape")
        head_out = gr.Dataframe(label="Sample Data")
        missing_out = gr.Dataframe(label="Missing Values")
        dtype_out = gr.Dataframe(label="Data Types")
        unique_out = gr.Dataframe(label="Unique Values")
        describe_out = gr.Dataframe(label="Descriptive Stats")
        corr_out = gr.Dataframe(label="Correlation with PM2.5")

        overview_btn = gr.Button("Show Overview")
        overview_btn.click(fn=show_data_info,
                           outputs=[shape_out, head_out, missing_out,
                                    dtype_out, unique_out, describe_out, corr_out])

    with gr.Tab("ðŸ“Š Exploratory Data Analysis"):
        feature_dropdown = gr.Dropdown(choices=[], label="Select Feature")
        plot_out = gr.Plot()
        eda_btn = gr.Button("Plot Distribution")

        eda_btn.click(fn=plot_eda, inputs=feature_dropdown, outputs=plot_out)
        file_input.change(fn=lambda f: gr.update(choices=pd.read_csv(f.name).columns.tolist()),
                          inputs=file_input, outputs=feature_dropdown)

    with gr.Tab("ðŸ§  Modeling and Prediction"):
        model_choice = gr.Radio(choices=["Random Forest", "Linear Regression","Gradient Boosting"], label="Choose Model")
        model_out = gr.Textbox(label="Model Performance")
        model_btn = gr.Button("Train & Predict")
        model_btn.click(fn=run_model, inputs=model_choice, outputs=model_out)

app.launch()

